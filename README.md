
# VizAV: Visualizing Autonomous Vehicle Data

ğŸš— **Interactive 3D Visualization and Analysis of Autonomous Driving Data**

## ğŸ¥ [Watch Presentation Video](https://drive.google.com/file/d/1nhkj5atlqu9xgPZlEwXpwk9me5LXh1tN/view?usp=sharing)

---

## ğŸ“š Project Description

VizAV is a project exploring large-scale autonomous driving datasets using the **Lyft L5 Prediction Dataset (100GB)** to understand how self-driving vehicles perceive and react to real-world urban environments.

Using **VizViewer**, an interactive 3D visualization platform, we analyze:
- Vehicle behavior
- Traffic patterns
- Agent movements (vehicles, pedestrians)
- Path prediction with lane-level analysis

---

## ğŸ› ï¸ Tools & Technologies
- **Python**
- **Jupyter Notebooks**
- **VizViewer (Web-based visualization)**
- Lyft L5 Prediction Dataset

---

## ğŸ” Key Features

âœ… 3D Semantic Map Visualization  
âœ… Synchronized Time-Series Graphs  
âœ… Heatmaps and Histograms for spatial behavior analysis  
âœ… Feature augmentation (speed, acceleration, yaw)  
âœ… Scene-level motion and interaction analysis  
âœ… Lane-level path prediction visualization

---

## ğŸ“ˆ Insights
- Identified patterns of vehicle behavior at intersections
- Analyzed agent density vs. ego vehicle speed
- Modeled vehicle path predictions with scene data
- Explored dataset biases and optimized feature engineering

---

## ğŸ¯ Future Work
- Expand dataset for broader urban scenarios
- Integrate additional sensor data for richer analysis
- Train full motion prediction models using augmented features
- Explore real-time visualization in simulation environments

---

## ğŸ‘©â€ğŸ’» Contributors
- Michelle Cain
- Hadar Daya
- Shir Berko

---

## ğŸ“ Resources
- [Lyft L5 Prediction Dataset](https://level5.lyft.com/dataset/)
- [VizViewer](https://github.com/lyft/l5kit)
