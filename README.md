
# VizAV: Visualizing Autonomous Vehicle Data

🚗 **Interactive 3D Visualization and Analysis of Autonomous Driving Data**

## 🎥 [Watch Presentation Video](https://drive.google.com/file/d/1nhkj5atlqu9xgPZlEwXpwk9me5LXh1tN/view?usp=sharing)

---

## 📚 Project Description

VizAV is a project exploring large-scale autonomous driving datasets using the **Lyft L5 Prediction Dataset (100GB)** to understand how self-driving vehicles perceive and react to real-world urban environments.

Using **VizViewer**, an interactive 3D visualization platform, we analyze:
- Vehicle behavior
- Traffic patterns
- Agent movements (vehicles, pedestrians)
- Path prediction with lane-level analysis

---

## 🛠️ Tools & Technologies
- **Python**
- **Jupyter Notebooks**
- **VizViewer (Web-based visualization)**
- Lyft L5 Prediction Dataset

---

## 🔍 Key Features

✅ 3D Semantic Map Visualization  
✅ Synchronized Time-Series Graphs  
✅ Heatmaps and Histograms for spatial behavior analysis  
✅ Feature augmentation (speed, acceleration, yaw)  
✅ Scene-level motion and interaction analysis  
✅ Lane-level path prediction visualization

---

## 📈 Insights
- Identified patterns of vehicle behavior at intersections
- Analyzed agent density vs. ego vehicle speed
- Modeled vehicle path predictions with scene data
- Explored dataset biases and optimized feature engineering

---

## 🎯 Future Work
- Expand dataset for broader urban scenarios
- Integrate additional sensor data for richer analysis
- Train full motion prediction models using augmented features
- Explore real-time visualization in simulation environments

---

## 👩‍💻 Contributors
- Michelle Cain
- Hadar Daya
- Shir Berko

---

## 📎 Resources
- [Lyft L5 Prediction Dataset](https://level5.lyft.com/dataset/)
- [VizViewer](https://github.com/lyft/l5kit)
